{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "\n",
    "#sc = SparkContext()\n",
    "sc=SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userinput(userinput1,userinput2,userinput3):\n",
    "    pages_list=[]\n",
    "    for i in range(1,int(userinput3)+1):\n",
    "        pages_list.append(f'https://www.simplyhired.com/search?q={userinput1}&l={userinput2}&sb=dd&pn={i}')#page1='https://www.simplyhired.com/search?q=big+data+engineer&l=united+states&sb=dd&pn=2'#&job=MrNtePJJR-mAmQM8Tiba5rnHB16pySp-UvaY0XdiWugpNfotFPsEtQ'        \n",
    "    return pages_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scraping(pages_list):\n",
    "        mydf=[]\n",
    "        total_jobs=0\n",
    "        for i in pages_list:\n",
    "                page = requests.get(i)\n",
    "                soup = BeautifulSoup(page.content, 'html.parser') # Access on the whole web front-end content\n",
    "                #print(soup)\n",
    "                #print(soup.find_all('a'))# find all links\n",
    "\n",
    "                job_container=soup.find(id=\"job-list\")#fAccess on the job-list container\n",
    "                #print(job_list)\n",
    "\n",
    "\n",
    "                jobs=job_container.find_all(class_ ='SerpJob')#Accessing all of the job listed\n",
    "                total_jobs+=len(jobs)\n",
    "                # for i in range(len(jobs)):\n",
    "                #         print(jobs[i].find(class_='jobposting-title-container').get_text())#title,\n",
    "                #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text())#company\n",
    "                #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text())#location\n",
    "                #         print(jobs[i].find(class_='jobposting-salary').get_text())#salary\n",
    "                #         print(jobs[i].find(class_='jobposting-snippet').get_text())#description\n",
    "                #         print(jobs[i].find(class_='SerpJob-timestamp').get_text())#date\n",
    "                #         #print(jobs[i].find(SerpJob-timestamp.datetime))#.get_text())#\n",
    "                #         #print(jobs[i].find_all('a'))# find all links      \n",
    "\n",
    "\n",
    "                titles=[jobs[i].find(class_='jobposting-title-container').get_text() for i in range(len(jobs))]\n",
    "                companies=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text() for i in range(len(jobs))]\n",
    "                locations=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text() for i in range(len(jobs))]\n",
    "                salaries=[jobs[i].find(class_='SerpJob-metaInfoLeft').get_text() for i in range(len(jobs))]#jobposting-salary\n",
    "                descriptions=[jobs[i].find(class_='jobposting-snippet').get_text() for i in range(len(jobs))]\n",
    "                timestamps=[jobs[i].find(class_='SerpJob-timestamp').get_text() for i in range(len(jobs))]\n",
    "                links=['https://www.simplyhired.com'+jobs[i].find('a').get('href') for i in range(len(jobs))]#\n",
    "\n",
    "\n",
    "                jobs_df=pd.DataFrame(\n",
    "                    {\n",
    "                      'Date':timestamps,\n",
    "                      'Job-title':titles,\n",
    "                      'Job-description':descriptions,\n",
    "                      'Location':locations,\n",
    "                      'Rate':salaries,\n",
    "                      'CompanY-name':companies,                    \n",
    "                      'Links':links\n",
    "\n",
    "                    })\n",
    "                mydf.append(jobs_df)# appending available df \n",
    "                \n",
    "        print('Sample link:')\n",
    "        print(links[2])        \n",
    "        result = pd.concat(mydf)\n",
    "        return total_jobs,result\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter the Title:data engineer\n",
      "Please Enter the Location:new york\n",
      "Please Enter the Number of Pages to search from:3\n",
      "Sample link:\n",
      "https://www.simplyhired.com/job/QaUjHEslu0ewFvCFiWyRaTOBdY0SpgxIQCNH0k7wIXzveoa0D_Wk0w?q=data+engineer\n",
      "Total Jobs: 57\n"
     ]
    }
   ],
   "source": [
    "userinput1=input('Please Enter the Title:')\n",
    "userinput2=input('Please Enter the Location:')\n",
    "userinput3=input('Please Enter the Number of Pages to search from:')\n",
    "\n",
    "pages_list = userinput(userinput1,userinput2,userinput3)\n",
    "total_jobs, result = scraping(pages_list)\n",
    "print('Total Jobs:',total_jobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "| Date|           Job-title|     Job-description|          Location|                Rate|        Company-name|                Link|\n",
      "+-----+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "|Today|Data Network Engi...|Develop, test, im...| Painted Post, NY |Estimated: $78,00...|             Corning|https://www.simpl...|\n",
      "|     |Validation Engine...|The Validation En...|      Norwich, NY |Estimated: $46,00...|Norwich Pharmaceu...|https://www.simpl...|\n",
      "|  12d|Sr. Project Engineer|Analyzes data to ...|East Syracuse, NY |$1,100 - $1,500 a...|       Infitec, Inc.|https://www.simpl...|\n",
      "|   7d|Business Data Eng...|Data Surveillance...|  Mount Kisco, NY |$80,000 - $100,00...|   ConvergeMarketing|https://www.simpl...|\n",
      "|     |System Engineer (...|Exposure to MES t...|    Cazenovia, NY |$75,000 - $100,00...|Knowles Precision...|https://www.simpl...|\n",
      "+-----+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mySchema = StructType([ StructField(\"Date\", StringType(), True)\\\n",
    "                       ,StructField(\"Job-title\", StringType(), True)\\\n",
    "                       ,StructField(\"Job-description\", StringType(), True)\\\n",
    "                       ,StructField(\"Location\", StringType(), True)\\\n",
    "                       ,StructField(\"Rate\", StringType(), True)\\\n",
    "                       ,StructField(\"Company-name\", StringType(), True)\\\n",
    "                       ,StructField(\"Link\", StringType(), True)])\n",
    "df = spark.createDataFrame(result,schema=mySchema)\n",
    "\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Dataframe into a Database as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| Date|           Job-title|     Job-description|            Location|                Rate|        Company-name|                Link|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Today|         QA Engineer|IEX Cloud is a fa...|       New York, NY |Estimated: $94,00...|           IEX Group|https://www.simpl...|\n",
      "|Today|Senior Data Analy...|Responsible for p...|     The Colony, TX |                    |Texas Health Reso...|https://www.simpl...|\n",
      "|Today|Data Network Engi...|Develop, test, im...|   Painted Post, NY |Estimated: $78,00...|             Corning|https://www.simpl...|\n",
      "|Today|Software Engineer...|As an experienced...|       New York, NY |Estimated: $100,0...|     JP Morgan Chase|https://www.simpl...|\n",
      "|     |Data Integration ...|The Data Integrat...|     Fort Worth, TX |Estimated: $85,00...|Cook Children's H...|https://www.simpl...|\n",
      "|     |       Test Engineer|Perform duties as...|    San Antonio, TX |Estimated: $81,00...|ManTech Internati...|https://www.simpl...|\n",
      "|     |Airframe Wiring I...|Ability to coordi...|     Fort Worth, TX |Estimated: $67,00...|              Cyient|https://www.simpl...|\n",
      "|Today|Geotechnical Engi...|Gathering, integr...|        Houston, TX |Estimated: $61,00...|         Phillips 66|https://www.simpl...|\n",
      "|Today|Senior Sales Engi...|Testing and docum...|         Austin, TX |Estimated: $86,00...|               Axzon|https://www.simpl...|\n",
      "|     |Embedded System E...|A Japanese IT ser...|         Dallas, TX |Estimated: $66,00...|Total Computing S...|https://www.simpl...|\n",
      "|Today|Marketing Applica...|Experience with a...|         Dallas, TX |Estimated: $72,00...|         Bosch Group|https://www.simpl...|\n",
      "|Today|TFT Device Modeli...|Develop SPICE mod...|       New York, NY |Estimated: $83,00...|             Lumiode|https://www.simpl...|\n",
      "|     |   Software Engineer|APIs, Business Lo...|         Austin, TX |Estimated: $93,00...|             eHealth|https://www.simpl...|\n",
      "|     |Swift iOS Develop...|Experience buildi...|       New York, NY |$55,000 - $70,000...|Lunchbox Technolo...|https://www.simpl...|\n",
      "|Today| Lead Data Scientist|Help design and b...|       New York, NY |Estimated: $100,0...|                 VTS|https://www.simpl...|\n",
      "|Today|Data Integration ...|3 Years Working a...|      Arlington, TX |                    |Texas Health Reso...|https://www.simpl...|\n",
      "|     |Signal Processing...|Validating suppli...|       Syracuse, NY |Estimated: $89,00...|In-Depth Engineer...|https://www.simpl...|\n",
      "|   3d|        ESD Engineer|Drive the develop...|         Albany, NY |Estimated: $76,00...|HFC Semiconductor...|https://www.simpl...|\n",
      "|Today|Java Software Eng...|Responsibilities ...|Plano, TX +1 loca...|Estimated: $110,0...|     JP Morgan Chase|https://www.simpl...|\n",
      "|     |Senior Software E...|Financial and acc...|       New York, NY |Estimated: $110,0...|Innovest Systems LLC|https://www.simpl...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "saving......1\n",
      "saving......done\n"
     ]
    }
   ],
   "source": [
    "#add the jar to the spark/jar to link spark to mysql (append or overwrite)\n",
    "try:\n",
    "    df1=spark.read.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').load()\n",
    "    df2=df1.union(df).distinct()#union of both leaving out duplicates\n",
    "    df2.show()\n",
    "    #df2=df.join(df1,'Link','leftanti').show()\n",
    "    #df1=df1.union(df2)\n",
    "    print('saving......1')\n",
    "    df2.write.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').mode('append').save()\n",
    "    print('saving......done')\n",
    "except:\n",
    "    print('Runing except')\n",
    "    df1= df\n",
    "    df1.write.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').mode('append').save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=E5cSNSeBhjw\n",
    "#https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "#https://hackersandslackers.com/scraping-urls-with-beautifulsoup/\n",
    "#https://opensource.com/article/19/5/log-data-apache-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S3\n",
    "#http://carolynlangen.com/2017/11/22/interacting-with-aws-s3-using-python-in-a-jupyter-notebook/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
