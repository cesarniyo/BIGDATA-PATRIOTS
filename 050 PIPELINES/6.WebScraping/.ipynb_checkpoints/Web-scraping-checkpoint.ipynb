{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "\n",
    "#sc = SparkContext()\n",
    "sc=SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userinput(userinput1,userinput2,userinput3):\n",
    "    pages_list=[]\n",
    "    for i in range(1,int(userinput3)+1):\n",
    "        pages_list.append(f'https://www.simplyhired.com/search?q={userinput1}&l={userinput2}&sb=dd&pn={i}')#page1='https://www.simplyhired.com/search?q=big+data+engineer&l=united+states&sb=dd&pn=2'#&job=MrNtePJJR-mAmQM8Tiba5rnHB16pySp-UvaY0XdiWugpNfotFPsEtQ'        \n",
    "    return pages_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scraping(userinput1,pages_list):\n",
    "        mydf=[]\n",
    "        total_jobs=0\n",
    "        for i in pages_list:\n",
    "                page = requests.get(i)\n",
    "                soup = BeautifulSoup(page.content, 'html.parser') # Access on the whole web front-end content\n",
    "                #print(soup)\n",
    "                #print(soup.find_all('a'))# find all links\n",
    "\n",
    "                job_container=soup.find(id=\"job-list\")#fAccess on the job-list container\n",
    "                #print(job_list)\n",
    "\n",
    "\n",
    "                jobs=job_container.find_all(class_ ='SerpJob')#Accessing all of the job listed\n",
    "                total_jobs+=len(jobs)\n",
    "                # for i in range(len(jobs)):\n",
    "                #         print(jobs[i].find(class_='jobposting-title-container').get_text())#title,\n",
    "                #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text())#company\n",
    "                #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text())#location\n",
    "                #         print(jobs[i].find(class_='jobposting-salary').get_text())#salary\n",
    "                #         print(jobs[i].find(class_='jobposting-snippet').get_text())#description\n",
    "                #         print(jobs[i].find(class_='SerpJob-timestamp').get_text())#date\n",
    "                #         #print(jobs[i].find(SerpJob-timestamp.datetime))#.get_text())#\n",
    "                #         #print(jobs[i].find_all('a'))# find all links      \n",
    "\n",
    "                searchKeyword=[userinput1 for i in range(len(jobs))]\n",
    "                titles=[jobs[i].find(class_='jobposting-title-container').get_text() for i in range(len(jobs))]\n",
    "                companies=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text() for i in range(len(jobs))]\n",
    "                locations=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text() for i in range(len(jobs))]\n",
    "                salaries=[jobs[i].find(class_='SerpJob-metaInfoLeft').get_text() for i in range(len(jobs))]#jobposting-salary\n",
    "                descriptions=[jobs[i].find(class_='jobposting-snippet').get_text() for i in range(len(jobs))]\n",
    "                timestamps=[jobs[i].find(class_='SerpJob-timestamp').get_text() for i in range(len(jobs))]\n",
    "                links=['https://www.simplyhired.com'+jobs[i].find('a').get('href') for i in range(len(jobs))]#\n",
    "                \n",
    "                #Spliting locations into Cities and States\n",
    "                cities=[]\n",
    "                states=[]\n",
    "                \n",
    "                for i in locations:\n",
    "                    loc=i.split(',')\n",
    "                    cities.append(loc[0])\n",
    "                    states.append(loc[-1])\n",
    "\n",
    "                    \n",
    "                    \n",
    "                jobs_df=pd.DataFrame(\n",
    "                    {  \n",
    "                      'Date':timestamps,\n",
    "                      'searchKeyword':searchKeyword,\n",
    "                      'Job-title':titles,\n",
    "                      'Job-description':descriptions,\n",
    "                      'City':cities,\n",
    "                      'State':states,\n",
    "                      'Rate':salaries,\n",
    "                      'CompanY-name':companies,                    \n",
    "                      'Links':links\n",
    "\n",
    "                    })\n",
    "                mydf.append(jobs_df)# appending available df \n",
    "                \n",
    "        print('Sample link:')\n",
    "        print(links[2])        \n",
    "        result = pd.concat(mydf)\n",
    "        return total_jobs,result\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter the Title:big data engineer\n",
      "Please Enter the Location:united states\n",
      "Please Enter the Number of Pages to search from:3\n",
      "Sample link:\n",
      "https://www.simplyhired.com/job/fV6AlIgo7v6LAJ13LH12rIHBanYzGW-MWD8CFJ2RNubveXvy2o6jZw?q=big+data+engineer\n",
      "Total Jobs: 57\n"
     ]
    }
   ],
   "source": [
    "userinput1=input('Please Enter the Title:')\n",
    "userinput2=input('Please Enter the Location:')\n",
    "userinput3=input('Please Enter the Number of Pages to search from:')\n",
    "\n",
    "pages_list = userinput(userinput1,userinput2,userinput3)\n",
    "total_jobs, result = scraping(userinput1,pages_list)\n",
    "print('Total Jobs:',total_jobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+--------------------+--------------------+--------------+-----+--------------------+-----------------+--------------------+\n",
      "| Date|    SearchKeyword|           Job-title|     Job-description|          City|State|                Rate|     Company-name|                Link|\n",
      "+-----+-----------------+--------------------+--------------------+--------------+-----+--------------------+-----------------+--------------------+\n",
      "|Today|big data engineer|Senior Data Engineer|Help manage Capsu...|      New York|  NY |Estimated: $120,0...|          Capsule|https://www.simpl...|\n",
      "|     |big data engineer|Engineer - Data &...|Coordinate with a...|Patuxent River|  MD |Estimated: $41,00...|              PAE|https://www.simpl...|\n",
      "|     |big data engineer|Business Data Eng...|Data Surveillance...|   Mount Kisco|  NY |$80,000 - $100,00...|ConvergeMarketing|https://www.simpl...|\n",
      "|     |big data engineer|Engieer - Data & ...|Coordinate with a...|Patuxent River|  MD |Estimated: $39,00...|              PAE|https://www.simpl...|\n",
      "|     |big data engineer|   Big Data Engineer|The CASLink Analy...|       Raleigh|  NC |Estimated: $69,00...|CaptiveAire, Inc.|https://www.simpl...|\n",
      "+-----+-----------------+--------------------+--------------------+--------------+-----+--------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mySchema = StructType([ StructField(\"Date\", StringType(), True)\\\n",
    "                       ,StructField(\"SearchKeyword\", StringType(), True)\\\n",
    "                       ,StructField(\"Job-title\", StringType(), True)\\\n",
    "                       ,StructField(\"Job-description\", StringType(), True)\\\n",
    "                       ,StructField(\"City\", StringType(), True)\\\n",
    "                       ,StructField(\"State\", StringType(), True)\\\n",
    "                       ,StructField(\"Rate\", StringType(), True)\\\n",
    "                       ,StructField(\"Company-name\", StringType(), True)\\\n",
    "                       ,StructField(\"Link\", StringType(), True)])\n",
    "df = spark.createDataFrame(result,schema=mySchema)\n",
    "\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Dataframe into a Database as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+\n",
      "| Date|    SearchKeyword|           Job-title|     Job-description|                City|           State|                Rate|        Company-name|                Link|\n",
      "+-----+-----------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+\n",
      "|Today|    Data engineer|FLIGHT SCIENCES E...|Wind tunnel and f...|             Seattle|             WA |Estimated: $86,00...|       TLG Aerospace|https://www.simpl...|\n",
      "|   4d|big data engineer|Data Operation En...|Experience with S...|San Francisco Bay...|             CA |$120,000 - $150,0...|          GridX,Inc.|https://www.simpl...|\n",
      "|     |    Data engineer|QA Automation Eng...|The QA Automation...|              Boston|             MA |Estimated: $96,00...|          CodaMetrix|https://www.simpl...|\n",
      "|     |    Data engineer|Program Lead Syst...|Provide technical...|  Annapolis Junction|             MD |Estimated: $98,00...|  ELTA North America|https://www.simpl...|\n",
      "|     |big data engineer|    System Architect|Work closely with...|              Boston|             MA |$120,000 - $180,0...|            iQuartic|https://www.simpl...|\n",
      "|  10d|big data engineer|Virtualization En...|Deploys, integrat...|Aberdeen Proving ...|             MD |$120,000 - $150,0...|       DCI Solutions|https://www.simpl...|\n",
      "|     |big data engineer|Data Integrator/D...|At least two year...|          Fort Bragg|             NC |Estimated: $99,00...|           RDR, Inc.|https://www.simpl...|\n",
      "|Today|big data engineer|Sr. Mgr/Director ...|Do you have a wor...|              McLean| VA +2 locations|Estimated: $120,0...|              Splunk|https://www.simpl...|\n",
      "|     |    Data engineer|System Engineer (...|Experience with L...|             Bedford|             MA |Estimated: $64,00...|   Oasis Systems LLC|https://www.simpl...|\n",
      "|Today|big data engineer|Big Data/Hadoop D...|We are looking fo...|             Atlanta|             GA |Estimated: $96,00...|               Spout|https://www.simpl...|\n",
      "|     |    Data engineer|Senior Geotechnic...|Colorado Professi...|              Denver|             CO |Estimated: $85,00...|     RJH Consultants|https://www.simpl...|\n",
      "|     |big data engineer|Senior Consultant...|As an Azure Data ...|              Boston|             MA |Estimated: $100,0...|             Avanade|https://www.simpl...|\n",
      "|Today|big data engineer|Sr. Software Deve...|Be part of big da...|            New York|             NY |                    |Amazon.com Servic...|https://www.simpl...|\n",
      "|Today|big data engineer|Data Infrastructu...|Data Infrastructu...|       Mountain View|             CA |Estimated: $120,0...|  Lightup Data, Inc.|https://www.simpl...|\n",
      "|     |    Data engineer|Business Data Eng...|Data Surveillance...|         Mount Kisco|             NY |$80,000 - $100,00...|   ConvergeMarketing|https://www.simpl...|\n",
      "|     |big data engineer|Informatics Data ...|Manage and Evolve...|       Basking Ridge|             NJ |Estimated: $110,0...|Daiichi Sankyo, Inc.|https://www.simpl...|\n",
      "|Today|big data engineer|Senior Data Quali...|Utilize data prof...|      United States |  United States |Estimated: $110,0...|           SpotRight|https://www.simpl...|\n",
      "|Today|    Data engineer|Splunk Engineer, ...|Log data, NetFlow...|          Washington|             DC |Estimated: $110,0...|By Light Professi...|https://www.simpl...|\n",
      "|Today|    Data engineer|Artificial Intell...|Part of a diverse...|          Cincinnati|             OH |                    |    Procter & Gamble|https://www.simpl...|\n",
      "|     |big data engineer|       Data Engineer|Experience workin...|         Hanscom AFB|             MA |Estimated: $92,00...|        OneGlobe LLC|https://www.simpl...|\n",
      "+-----+-----------------+--------------------+--------------------+--------------------+----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "saving......1\n",
      "saving......done\n"
     ]
    }
   ],
   "source": [
    "#add the jar to the spark/jar to link spark to mysql (append or overwrite)\n",
    "try:\n",
    "    df1=spark.read.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').load()\n",
    "    df2=df1.union(df).distinct()#union of both leaving out duplicates\n",
    "    df2.show()\n",
    "    #df2=df.join(df1,'Link','leftanti').show()\n",
    "    #df1=df1.union(df2)\n",
    "    print('saving......1')\n",
    "    df2.write.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').mode('append').save()\n",
    "    print('saving......done')\n",
    "except:\n",
    "    print('Runing except')\n",
    "    df1= df\n",
    "    df1.write.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').mode('append').save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=E5cSNSeBhjw\n",
    "#https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "#https://hackersandslackers.com/scraping-urls-with-beautifulsoup/\n",
    "#https://opensource.com/article/19/5/log-data-apache-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S3\n",
    "#http://carolynlangen.com/2017/11/22/interacting-with-aws-s3-using-python-in-a-jupyter-notebook/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
