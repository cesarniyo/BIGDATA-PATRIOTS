{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.context import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "\n",
    "#sc = SparkContext()\n",
    "sc=SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userinput(userinput1,userinput2,userinput3):\n",
    "    pages_list=[]\n",
    "    for i in range(1,int(userinput3)+1):\n",
    "        pages_list.append(f'https://www.simplyhired.com/search?q={userinput1}&l={userinput2}&sb=dd&pn={i}')#page1='https://www.simplyhired.com/search?q=big+data+engineer&l=united+states&sb=dd&pn=2'#&job=MrNtePJJR-mAmQM8Tiba5rnHB16pySp-UvaY0XdiWugpNfotFPsEtQ'        \n",
    "    return pages_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scraping(userinput1,pages_list):\n",
    "        mydf=[]\n",
    "        total_jobs=0\n",
    "        for i in pages_list:\n",
    "                page = requests.get(i)\n",
    "                soup = BeautifulSoup(page.content, 'html.parser') # Access on the whole web front-end content\n",
    "                #print(soup)\n",
    "                #print(soup.find_all('a'))# find all links\n",
    "\n",
    "                job_container=soup.find(id=\"job-list\")#fAccess on the job-list container\n",
    "                #print(job_list)\n",
    "\n",
    "\n",
    "                jobs=job_container.find_all(class_ ='SerpJob')#Accessing all of the job listed\n",
    "                total_jobs+=len(jobs)\n",
    "                # for i in range(len(jobs)):\n",
    "                #         print(jobs[i].find(class_='jobposting-title-container').get_text())#title,\n",
    "                #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text())#company\n",
    "                #         print(jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text())#location\n",
    "                #         print(jobs[i].find(class_='jobposting-salary').get_text())#salary\n",
    "                #         print(jobs[i].find(class_='jobposting-snippet').get_text())#description\n",
    "                #         print(jobs[i].find(class_='SerpJob-timestamp').get_text())#date\n",
    "                #         #print(jobs[i].find(SerpJob-timestamp.datetime))#.get_text())#\n",
    "                #         #print(jobs[i].find_all('a'))# find all links      \n",
    "\n",
    "                searchKeyword=[userinput1 for i in range(len(jobs))]\n",
    "                titles=[jobs[i].find(class_='jobposting-title-container').get_text() for i in range(len(jobs))]\n",
    "                companies=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-company').get_text() for i in range(len(jobs))]\n",
    "                locations=[jobs[i].find(class_='JobPosting-labelWithIcon jobposting-location').get_text() for i in range(len(jobs))]\n",
    "                salaries=[jobs[i].find(class_='SerpJob-metaInfoLeft').get_text() for i in range(len(jobs))]#jobposting-salary\n",
    "                descriptions=[jobs[i].find(class_='jobposting-snippet').get_text() for i in range(len(jobs))]\n",
    "                timestamps=[jobs[i].find(class_='SerpJob-timestamp').get_text() for i in range(len(jobs))]\n",
    "                links=['https://www.simplyhired.com'+jobs[i].find('a').get('href') for i in range(len(jobs))]#\n",
    "                \n",
    "                #Spliting locations into Cities and States\n",
    "                cities=[]\n",
    "                states=[]\n",
    "                \n",
    "                for i in locations:\n",
    "                    loc=i.split(',')\n",
    "                    cities.append(loc[0])\n",
    "                    states.append(loc[-1])\n",
    "\n",
    "                    \n",
    "                    \n",
    "                jobs_df=pd.DataFrame(\n",
    "                    {  \n",
    "                      'Date':timestamps,\n",
    "                      'searchKeyword':searchKeyword,\n",
    "                      'Job-title':titles,\n",
    "                      'Job-description':descriptions,\n",
    "                      'City':cities,\n",
    "                      'State':states,\n",
    "                      'Rate':salaries,\n",
    "                      'CompanY-name':companies,                    \n",
    "                      'Links':links\n",
    "\n",
    "                    })\n",
    "                mydf.append(jobs_df)# appending available df \n",
    "        \n",
    "        print('Sample link:')\n",
    "        print(links[2])        \n",
    "        result = pd.concat(mydf)\n",
    "        return total_jobs,result\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter the Title:Data engineer\n",
      "Please Enter the Location:Dallas\n",
      "Please Enter the Number of Pages to search from:2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fulltime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-872ad6f655e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpages_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserinput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserinput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muserinput2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muserinput3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtotal_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserinput1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpages_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Jobs:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c09550967002>\u001b[0m in \u001b[0;36mscraping\u001b[0;34m(userinput1, pages_list)\u001b[0m\n\u001b[1;32m     67\u001b[0m                     })\n\u001b[1;32m     68\u001b[0m                 \u001b[0mmydf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# appending available df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample link:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fulltime' is not defined"
     ]
    }
   ],
   "source": [
    "userinput1=input('Please Enter the Title:')\n",
    "userinput2=input('Please Enter the Location:')\n",
    "userinput3=input('Please Enter the Number of Pages to search from:')\n",
    "\n",
    "pages_list = userinput(userinput1,userinput2,userinput3)\n",
    "total_jobs, result = scraping(userinput1,pages_list)\n",
    "print('Total Jobs:',total_jobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mySchema = StructType([ StructField(\"Date\", StringType(), True)\\\n",
    "                       ,StructField(\"SearchKeyword\", StringType(), True)\\\n",
    "                       ,StructField(\"Job-title\", StringType(), True)\\\n",
    "                       ,StructField(\"Job-description\", StringType(), True)\\\n",
    "                       ,StructField(\"City\", StringType(), True)\\\n",
    "                       ,StructField(\"State\", StringType(), True)\\\n",
    "                       ,StructField(\"Rate\", StringType(), True)\\\n",
    "                       ,StructField(\"Company-name\", StringType(), True)\\\n",
    "                       ,StructField(\"Link\", StringType(), True)])\n",
    "df = spark.createDataFrame(result,schema=mySchema)\n",
    "\n",
    "df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Dataframe into a Database as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the jar to the spark/jar to link spark to mysql (append or overwrite)\n",
    "try:\n",
    "    df1=spark.read.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').load()\n",
    "    df2=df1.union(df).distinct()#union of both leaving out duplicates\n",
    "    df2.show()\n",
    "    #df2=df.join(df1,'Link','leftanti').show()\n",
    "    #df1=df1.union(df2)\n",
    "    print('saving......1')\n",
    "    df2.write.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').mode('append').save()\n",
    "    print('saving......done')\n",
    "except:\n",
    "    print('Runing except')\n",
    "    df1= df\n",
    "    df1.write.format('jdbc').options(url='jdbc:mysql://mydb.cqdk5nbfyybo.us-east-2.rds.amazonaws.com:3306/mydb',driver='com.mysql.jdbc.Driver',dbtable='SIMPLYHIRED',user='admin',password='Password').mode('append').save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=E5cSNSeBhjw\n",
    "#https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "#https://hackersandslackers.com/scraping-urls-with-beautifulsoup/\n",
    "#https://opensource.com/article/19/5/log-data-apache-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S3\n",
    "#http://carolynlangen.com/2017/11/22/interacting-with-aws-s3-using-python-in-a-jupyter-notebook/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
